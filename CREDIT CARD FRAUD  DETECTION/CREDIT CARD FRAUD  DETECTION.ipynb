import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score, precision_recall_curve
)
from imblearn.under_sampling import RandomUnderSampler
import joblib

# Load the dataset
df = pd.read_csv('fraudTest.csv')

# Display basic info
print("Dataset Info:")
print(df.info())
print("\nClass Distribution:")
print(df['is_fraud'].value_counts())
df.fillna({
    'city': 'Unknown',
    'state': 'Unknown',
    'zip': 0,
    'lat': df['lat'].mean(),
    'long': df['long'].mean(),
    'city_pop': df['city_pop'].mean(),
    'job': 'Unknown',
    'dob': '1900-01-01',  
    'trans_num': 'Unknown',
    'merch_lat': df['merch_lat'].mean(),
    'merch_long': df['merch_long'].mean(),
    'unix_time': df['unix_time'].mean(),  #
    'is_fraud': 0  
}, inplace=True)

print("\nRemaining Missing Values:")
print(df.isnull().sum())


features = ['amt', 'city_pop', 'lat', 'long', 'merch_lat', 'merch_long']
X = df[features]
y = df['is_fraud']


if y.isnull().any():
    print("Target variable contains NaN values. Please check the data.")
else:
    rus = RandomUnderSampler(random_state=42)
    X_resampled, y_resampled = rus.fit_resample(X, y)
    X_train, X_test, y_train, y_test = train_test_split(
        X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    models = {
        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
        'Decision Tree': DecisionTreeClassifier(random_state=42),
        'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100) }
    results = []
    for name, model in models.items():
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        y_prob = model.predict_proba(X_test_scaled)[:, 1]
        
        # Calculate metrics
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        roc_auc = roc_auc_score(y_test, y_prob)
        
        results.append({
            'Model': name,
            'Accuracy': accuracy,
            'Precision': precision,
            'Recall': recall,
            'F1 Score': f1,
            'ROC AUC': roc_auc
        })
        
        # Print classification report
        print(f"\n{name} Classification Report:")
        print(classification_report(y_test, y_pred))
        
        # Plot confusion matrix
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(4, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
        plt.title(f'{name} Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.show()
        
        # Plot Precision-Recall curve
        precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_prob)
        plt.figure(figsize=(6, 4))
        plt.plot(recall_vals, precision_vals, marker='.')
        plt.title(f'{name} Precision-Recall Curve')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.show()

    # Display results
    results_df = pd.DataFrame(results)
    print("\nModel Comparison:")
    print(results_df)

    # Save the best model (based on your evaluation)
    best_model = RandomForestClassifier(random_state=42, n_estimators=100)
    best_model.fit(X_train_scaled, y_train)
    joblib.dump(best_model, 'fraud_detection_model.pkl')
    joblib.dump(scaler, 'scaler.pkl')

    print("\nBest model (Random Forest) and scaler saved to disk.")
